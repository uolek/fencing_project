{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import pickle\n",
    "#import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FencingPool:\n",
    "    \n",
    "    def __init__(self, ident, imported):\n",
    "        self.ident = ident\n",
    "        self.date = str(datetime.date.today())\n",
    "        self.results = imported[0]\n",
    "        self.names = imported[1]\n",
    "        \n",
    "    def get_results(self):\n",
    "        print(self.results)\n",
    "        \n",
    "class Fencer:\n",
    "    \n",
    "    def __init__(self, ident, name):\n",
    "        self.ident = ident\n",
    "        self.name = name\n",
    "        \n",
    "def pool_importer(pool_loc=\"./pool_test_csv.csv\"):\n",
    "    \n",
    "    #types = '<U12,i8,i8,i8'\n",
    "    #pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=',', dtype=types, skip_header=1)\n",
    "    \n",
    "    with open(\"./pool_test_csv.csv\") as f:\n",
    "        ncols = len(f.readline().split(','))\n",
    "    pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=',', dtype=None, skip_header=1, usecols=range(1,ncols))\n",
    "    names = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=',', dtype='<U12', skip_header=1, usecols=0)\n",
    "    \n",
    "    return pool, names\n",
    "\n",
    "def load_database(filename):\n",
    "    \n",
    "    with open(filename,'rb') as file_object: \n",
    "        db = pickle.load(file_object)\n",
    "        \n",
    "    return db\n",
    "\n",
    "def save_database(db, filename):\n",
    "    \n",
    "    with open(filename, 'wb') as file_object:\n",
    "        pickle.dump(db, file_object)\n",
    "        \n",
    "    \n",
    "def add_pool_to_database(pool, filename):\n",
    "    \n",
    "    fencer_to_id, id_to_fencer, pool_to_id, id_to_pool, pools, fencers = load_database(filename)\n",
    "    \n",
    "    for name in pool.names:\n",
    "        if name not in fencer_to_id:\n",
    "            new_id = max(id_to_fencer)+1\n",
    "            fencer_to_id[name] = new_id\n",
    "            id_to_fencer[new_id] = name\n",
    "    \n",
    "    pools.append(pool)\n",
    "    \n",
    "    save_database([fencer_to_id, id_to_fencer, pool_to_id, id_to_pool, pools, fencers], filename)\n",
    "    \n",
    "def initialize_database(filename):\n",
    "    \n",
    "    # order is: fencer_to_id, id_to_fencer, pool_to_id, id_to_pool, pools, fencers\n",
    "    db = [{},{1000: 'no student'},{}, {1000: 'no pool'}, [], []]\n",
    "    with open(filename, 'wb') as file_object:\n",
    "        pickle.dump(db, file_object)\n",
    "        \n",
    "def construct_results_array_from_database(filename):\n",
    "    \n",
    "    db = load_database(filename)\n",
    "    num_fencers = len(database[0])\n",
    "    num_pools = len(database[2])\n",
    "    \n",
    "    results_array = np.zeros((num_pools, num_fencers+1, num_fencers+1), dtype=int)-1\n",
    "    results_array[:,0,1:] = [*database[1].keys()][1:]\n",
    "    results_array[:,1:,0] = [*database[1].keys()][1:]\n",
    "    \n",
    "    for i in range(len(database[2])):\n",
    "        results_array[i,0,0] = database[2][i].ident\n",
    "        results_array[i,1:num_fencers+1,1:num_fencers+1] = database[2][i].results\n",
    "\n",
    "    return results_array\n",
    "    \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pool1 = FencingPool(1, pool_importer())\n",
    "pool2 = FencingPool(2, pool_importer())\n",
    "pool3 = FencingPool(3, pool_importer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'data.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_database(filename)\n",
    "fencer_to_id, id_to_fencer, pool_to_id, id_to_pool, pools, fencers = load_database(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Alice': 1001, 'Bob': 1002, 'Chuck': 1003}, {1000: 'no student', 1001: 'Alice', 1002: 'Bob', 1003: 'Chuck'}, {}, {1000: 'no pool'}, [<__main__.FencingPool object at 0x000001CD71681A20>, <__main__.FencingPool object at 0x000001CD716BEEB8>, <__main__.FencingPool object at 0x000001CD716BEC18>], []]\n"
     ]
    }
   ],
   "source": [
    "add_pool_to_database(pool1, filename)\n",
    "add_pool_to_database(pool2, filename)\n",
    "add_pool_to_database(pool3, filename)\n",
    "database = load_database(filename)\n",
    "print(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_database(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added objects:\n",
      "fencer_to_id\n",
      "id_to_fencer\n",
      "pool_to_id\n",
      "id_to_pool\n",
      "pools\n",
      "fencers\n"
     ]
    }
   ],
   "source": [
    "load_database(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fencer_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = [fencer_to_id, 'id_to_fencer', 'pool_to_id', 'id_to_pool', 'pools', 'fencers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fencer_to_id\n",
      "id_to_fencer\n",
      "pool_to_id\n",
      "id_to_pool\n",
      "pools\n",
      "fencers\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(db[1])):\n",
    "    print(db[1][i])\n",
    "    globals()[db[1][i]] = db[0][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 2,\n",
       " 'Fencer': __main__.Fencer,\n",
       " 'FencingPool': __main__.FencingPool,\n",
       " 'In': ['',\n",
       "  'results_array[results_array[:,0,:] == 1001]',\n",
       "  'import numpy as np\\nimport datetime\\nimport pickle\\n#import pandas as pd',\n",
       "  'class FencingPool:\\n    \\n    def __init__(self, ident, imported):\\n        self.ident = ident\\n        self.date = str(datetime.date.today())\\n        self.results = imported[0]\\n        self.names = imported[1]\\n        \\n    def get_results(self):\\n        print(self.results)\\n        \\nclass Fencer:\\n    \\n    def __init__(self):\\n        \\n        \\ndef pool_importer(pool_loc=\"./pool_test_csv.csv\"):\\n    \\n    #types = \\'<U12,i8,i8,i8\\'\\n    #pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=types, skip_header=1)\\n    \\n    with open(\"./pool_test_csv.csv\") as f:\\n        ncols = len(f.readline().split(\\',\\'))\\n    pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=None, skip_header=1, usecols=range(1,ncols))\\n    names = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=\\'<U12\\', skip_header=1, usecols=0)\\n    \\n    return pool, names\\n\\ndef load_database(filename):\\n    \\n    with open(filename,\\'rb\\') as file_object: \\n        db = pickle.load(file_object)\\n    return db\\n    \\ndef add_pool_to_database(pool, filename):\\n    \\n    db = load_database(filename)\\n    \\n    for name in pool.names:\\n        if name not in db[0]:\\n            new_id = max(db[1])+1\\n            db[0][name] = new_id\\n            db[1][new_id] = name\\n    \\n    db[2].append(pool)\\n    \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n    \\ndef initialize_database(filename):\\n    \\n    db = [{},{1000: \\'no student\\'},[]]    \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n        \\ndef construct_results_array_from_database(filename):\\n    \\n    db = load_database(filename)\\n    num_fencers = len(database[0])\\n    num_pools = len(database[2])\\n    \\n    results_array = np.zeros((num_pools, num_fencers+1, num_fencers+1), dtype=int)-1\\n    results_array[:,0,1:] = [*database[1].keys()][1:]\\n    results_array[:,1:,0] = [*database[1].keys()][1:]\\n    \\n    for i in range(len(database[2])):\\n        results_array[i,0,0] = database[2][i].ident\\n        results_array[i,1:num_fencers+1,1:num_fencers+1] = database[2][i].results\\n\\n    return results_array\\n    \\n\\n\\n        ',\n",
       "  'class FencingPool:\\n    \\n    def __init__(self, ident, imported):\\n        self.ident = ident\\n        self.date = str(datetime.date.today())\\n        self.results = imported[0]\\n        self.names = imported[1]\\n        \\n    def get_results(self):\\n        print(self.results)\\n        \\n#class Fencer:\\n    \\n #   def __init__(self):\\n        \\n        \\ndef pool_importer(pool_loc=\"./pool_test_csv.csv\"):\\n    \\n    #types = \\'<U12,i8,i8,i8\\'\\n    #pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=types, skip_header=1)\\n    \\n    with open(\"./pool_test_csv.csv\") as f:\\n        ncols = len(f.readline().split(\\',\\'))\\n    pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=None, skip_header=1, usecols=range(1,ncols))\\n    names = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=\\'<U12\\', skip_header=1, usecols=0)\\n    \\n    return pool, names\\n\\ndef load_database(filename):\\n    \\n    with open(filename,\\'rb\\') as file_object: \\n        db = pickle.load(file_object)\\n    return db\\n    \\ndef add_pool_to_database(pool, filename):\\n    \\n    db = load_database(filename)\\n    \\n    for name in pool.names:\\n        if name not in db[0]:\\n            new_id = max(db[1])+1\\n            db[0][name] = new_id\\n            db[1][new_id] = name\\n    \\n    db[2].append(pool)\\n    \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n    \\ndef initialize_database(filename):\\n    \\n    db = [{},{1000: \\'no student\\'},[]]    \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n        \\ndef construct_results_array_from_database(filename):\\n    \\n    db = load_database(filename)\\n    num_fencers = len(database[0])\\n    num_pools = len(database[2])\\n    \\n    results_array = np.zeros((num_pools, num_fencers+1, num_fencers+1), dtype=int)-1\\n    results_array[:,0,1:] = [*database[1].keys()][1:]\\n    results_array[:,1:,0] = [*database[1].keys()][1:]\\n    \\n    for i in range(len(database[2])):\\n        results_array[i,0,0] = database[2][i].ident\\n        results_array[i,1:num_fencers+1,1:num_fencers+1] = database[2][i].results\\n\\n    return results_array\\n    \\n\\n\\n        ',\n",
       "  'pool1 = FencingPool(1, pool_importer())\\npool2 = FencingPool(2, pool_importer())\\npool3 = FencingPool(3, pool_importer())',\n",
       "  \"filename = 'testfile'\",\n",
       "  'initialize_database(filename)\\ndatabase = load_database(filename)\\nprint(database)',\n",
       "  'add_pool_to_database(pool1, filename)\\nadd_pool_to_database(pool2, filename)\\nadd_pool_to_database(pool3, filename)\\ndatabase = load_database(filename)\\nprint(database)',\n",
       "  'results_array = construct_results_array_from_database(filename)',\n",
       "  'results_array',\n",
       "  'results_array[results_array[:,0,:] == 1001]',\n",
       "  'class FencingPool:\\n    \\n    def __init__(self, ident, imported):\\n        self.ident = ident\\n        self.date = str(datetime.date.today())\\n        self.results = imported[0]\\n        self.names = imported[1]\\n        \\n    def get_results(self):\\n        print(self.results)\\n        \\nclass Fencer:\\n    \\n    def __init__(self, ident, name):\\n        self.ident = ident\\n        self.name = name\\n        \\ndef pool_importer(pool_loc=\"./pool_test_csv.csv\"):\\n    \\n    #types = \\'<U12,i8,i8,i8\\'\\n    #pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=types, skip_header=1)\\n    \\n    with open(\"./pool_test_csv.csv\") as f:\\n        ncols = len(f.readline().split(\\',\\'))\\n    pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=None, skip_header=1, usecols=range(1,ncols))\\n    names = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=\\'<U12\\', skip_header=1, usecols=0)\\n    \\n    return pool, names\\n\\ndef load_database(filename):\\n    \\n    with open(filename,\\'rb\\') as file_object: \\n        db = pickle.load(file_object)\\n    return db\\n    \\ndef add_pool_to_database(pool, filename):\\n    \\n    db = load_database(filename)\\n    \\n    for name in pool.names:\\n        if name not in db[0]:\\n            new_id = max(db[1])+1\\n            db[0][name] = new_id\\n            db[1][new_id] = name\\n    \\n    db[2].append(pool)\\n    \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n    \\ndef initialize_database(filename):\\n    \\n    db = [{},{1000: \\'no student\\'},[]]    \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n        \\ndef construct_results_array_from_database(filename):\\n    \\n    db = load_database(filename)\\n    num_fencers = len(database[0])\\n    num_pools = len(database[2])\\n    \\n    results_array = np.zeros((num_pools, num_fencers+1, num_fencers+1), dtype=int)-1\\n    results_array[:,0,1:] = [*database[1].keys()][1:]\\n    results_array[:,1:,0] = [*database[1].keys()][1:]\\n    \\n    for i in range(len(database[2])):\\n        results_array[i,0,0] = database[2][i].ident\\n        results_array[i,1:num_fencers+1,1:num_fencers+1] = database[2][i].results\\n\\n    return results_array\\n    \\n\\n\\n        ',\n",
       "  'x = 3',\n",
       "  \"pickle.dump(x, './test.log')\",\n",
       "  \"with open('./test.log', 'wb') as file_object:\\n        pickle.dump(db, file_object)\",\n",
       "  \"with open('./test.log', 'wb') as file_object:\\n        pickle.dump(x, file_object)\",\n",
       "  \"with open('./test.log','rb') as file_object: \\n    db = pickle.load(file_object)\",\n",
       "  'db',\n",
       "  'x = [4,5]',\n",
       "  \"with open('./test.log', 'wb') as file_object:\\n        pickle.dump(x, file_object)\",\n",
       "  \"with open('./test.log','rb') as file_object: \\n    db = pickle.load(file_object)\",\n",
       "  'db',\n",
       "  'x = [(3,4),5]',\n",
       "  \"with open('./test.log', 'wb') as file_object:\\n        pickle.dump(x, file_object)\",\n",
       "  \"with open('./test.log','rb') as file_object: \\n    db = pickle.load(file_object)\",\n",
       "  'db',\n",
       "  'db[0]',\n",
       "  'class FencingPool:\\n    \\n    def __init__(self, ident, imported):\\n        self.ident = ident\\n        self.date = str(datetime.date.today())\\n        self.results = imported[0]\\n        self.names = imported[1]\\n        \\n    def get_results(self):\\n        print(self.results)\\n        \\nclass Fencer:\\n    \\n    def __init__(self, ident, name):\\n        self.ident = ident\\n        self.name = name\\n        \\ndef pool_importer(pool_loc=\"./pool_test_csv.csv\"):\\n    \\n    #types = \\'<U12,i8,i8,i8\\'\\n    #pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=types, skip_header=1)\\n    \\n    with open(\"./pool_test_csv.csv\") as f:\\n        ncols = len(f.readline().split(\\',\\'))\\n    pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=None, skip_header=1, usecols=range(1,ncols))\\n    names = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=\\'<U12\\', skip_header=1, usecols=0)\\n    \\n    return pool, names\\n\\ndef load_database(filename):\\n    \\n    with open(filename,\\'rb\\') as file_object: \\n        db = pickle.load(file_object)\\n    return db\\n    \\ndef add_pool_to_database(pool, filename):\\n    \\n    db = load_database(filename)\\n    \\n    for name in pool.names:\\n        if name not in db[0]:\\n            new_id = max(db[1])+1\\n            db[0][name] = new_id\\n            db[1][new_id] = name\\n    \\n    db[2].append(pool)\\n    \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n    \\ndef initialize_database(filename):\\n    \\n    labels = (\\'fencer to id\\', \\'id to fencer\\', \\'pool to id\\', \\'id to pool\\', \\'pools\\', \\'fencers\\')\\n    db = [{},{1000: \\'no student\\'},{}, {1000: \\'no pool\\'}, [], []]   \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n        \\ndef construct_results_array_from_database(filename):\\n    \\n    db = load_database(filename)\\n    num_fencers = len(database[0])\\n    num_pools = len(database[2])\\n    \\n    results_array = np.zeros((num_pools, num_fencers+1, num_fencers+1), dtype=int)-1\\n    results_array[:,0,1:] = [*database[1].keys()][1:]\\n    results_array[:,1:,0] = [*database[1].keys()][1:]\\n    \\n    for i in range(len(database[2])):\\n        results_array[i,0,0] = database[2][i].ident\\n        results_array[i,1:num_fencers+1,1:num_fencers+1] = database[2][i].results\\n\\n    return results_array\\n    \\n\\n\\n        ',\n",
       "  'class FencingPool:\\n    \\n    def __init__(self, ident, imported):\\n        self.ident = ident\\n        self.date = str(datetime.date.today())\\n        self.results = imported[0]\\n        self.names = imported[1]\\n        \\n    def get_results(self):\\n        print(self.results)\\n        \\nclass Fencer:\\n    \\n    def __init__(self, ident, name):\\n        self.ident = ident\\n        self.name = name\\n        \\ndef pool_importer(pool_loc=\"./pool_test_csv.csv\"):\\n    \\n    #types = \\'<U12,i8,i8,i8\\'\\n    #pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=types, skip_header=1)\\n    \\n    with open(\"./pool_test_csv.csv\") as f:\\n        ncols = len(f.readline().split(\\',\\'))\\n    pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=None, skip_header=1, usecols=range(1,ncols))\\n    names = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=\\'<U12\\', skip_header=1, usecols=0)\\n    \\n    return pool, names\\n\\ndef load_database(filename):\\n    \\n    with open(filename,\\'rb\\') as file_object: \\n        db = pickle.load(file_object)\\n    return db\\n    \\ndef add_pool_to_database(pool, filename):\\n    \\n    db = load_database(filename)\\n    \\n    for name in pool.names:\\n        if name not in db[0]:\\n            new_id = max(db[1])+1\\n            db[0][name] = new_id\\n            db[1][new_id] = name\\n    \\n    db[2].append(pool)\\n    \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n    \\ndef initialize_database(filename):\\n    \\n    labels = (\\'fencer to id\\', \\'id to fencer\\', \\'pool to id\\', \\'id to pool\\', \\'pools\\', \\'fencers\\')\\n    db = ([{},{1000: \\'no student\\'},{}, {1000: \\'no pool\\'}, [], []], labels)\\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n        \\ndef construct_results_array_from_database(filename):\\n    \\n    db = load_database(filename)\\n    num_fencers = len(database[0])\\n    num_pools = len(database[2])\\n    \\n    results_array = np.zeros((num_pools, num_fencers+1, num_fencers+1), dtype=int)-1\\n    results_array[:,0,1:] = [*database[1].keys()][1:]\\n    results_array[:,1:,0] = [*database[1].keys()][1:]\\n    \\n    for i in range(len(database[2])):\\n        results_array[i,0,0] = database[2][i].ident\\n        results_array[i,1:num_fencers+1,1:num_fencers+1] = database[2][i].results\\n\\n    return results_array\\n    \\n\\n\\n        ',\n",
       "  \"filename = 'data.log'\",\n",
       "  'initialize_database',\n",
       "  'initialize_database(filename)',\n",
       "  'class FencingPool:\\n    \\n    def __init__(self, ident, imported):\\n        self.ident = ident\\n        self.date = str(datetime.date.today())\\n        self.results = imported[0]\\n        self.names = imported[1]\\n        \\n    def get_results(self):\\n        print(self.results)\\n        \\nclass Fencer:\\n    \\n    def __init__(self, ident, name):\\n        self.ident = ident\\n        self.name = name\\n        \\ndef pool_importer(pool_loc=\"./pool_test_csv.csv\"):\\n    \\n    #types = \\'<U12,i8,i8,i8\\'\\n    #pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=types, skip_header=1)\\n    \\n    with open(\"./pool_test_csv.csv\") as f:\\n        ncols = len(f.readline().split(\\',\\'))\\n    pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=None, skip_header=1, usecols=range(1,ncols))\\n    names = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=\\'<U12\\', skip_header=1, usecols=0)\\n    \\n    return pool, names\\n\\ndef load_database(filename):\\n    \\n    with open(filename,\\'rb\\') as file_object: \\n        db = pickle.load(file_object)\\n    return db\\n    \\ndef add_pool_to_database(pool, filename):\\n    \\n    db = load_database(filename)\\n    \\n    for name in pool.names:\\n        if name not in db[0]:\\n            new_id = max(db[1])+1\\n            db[0][name] = new_id\\n            db[1][new_id] = name\\n    \\n    db[2].append(pool)\\n    \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n    \\ndef initialize_database(filename):\\n    \\n    labels = (\\'fencer_to_id\\', \\'id_to_fencer\\', \\'pool_to_id\\', \\'id_to_pool\\', \\'pools\\', \\'fencers\\')\\n    db = ([{},{1000: \\'no student\\'},{}, {1000: \\'no pool\\'}, [], []], labels)\\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n        \\ndef construct_results_array_from_database(filename):\\n    \\n    db = load_database(filename)\\n    num_fencers = len(database[0])\\n    num_pools = len(database[2])\\n    \\n    results_array = np.zeros((num_pools, num_fencers+1, num_fencers+1), dtype=int)-1\\n    results_array[:,0,1:] = [*database[1].keys()][1:]\\n    results_array[:,1:,0] = [*database[1].keys()][1:]\\n    \\n    for i in range(len(database[2])):\\n        results_array[i,0,0] = database[2][i].ident\\n        results_array[i,1:num_fencers+1,1:num_fencers+1] = database[2][i].results\\n\\n    return results_array\\n    \\n\\n\\n        ',\n",
       "  'initialize_database(filename)',\n",
       "  \"with open(filename,'rb') as file_object: \\n    db = pickle.load(file_object)\",\n",
       "  'db',\n",
       "  'db[0]',\n",
       "  'db[1]',\n",
       "  'for label in db[1]:\\n    print label',\n",
       "  'for label in db[1]:\\n    print(label)',\n",
       "  'for i in range(len(db[1])):\\n    print(db[1][i])',\n",
       "  'for i in range(len(db[1])):\\n    print(db[1][i])\\n    db[1][i] = db[0][i]',\n",
       "  'db[1]',\n",
       "  'db[1] = db[0]',\n",
       "  'db[1]',\n",
       "  'db[*1]',\n",
       "  'db[1]',\n",
       "  'class FencingPool:\\n    \\n    def __init__(self, ident, imported):\\n        self.ident = ident\\n        self.date = str(datetime.date.today())\\n        self.results = imported[0]\\n        self.names = imported[1]\\n        \\n    def get_results(self):\\n        print(self.results)\\n        \\nclass Fencer:\\n    \\n    def __init__(self, ident, name):\\n        self.ident = ident\\n        self.name = name\\n        \\ndef pool_importer(pool_loc=\"./pool_test_csv.csv\"):\\n    \\n    #types = \\'<U12,i8,i8,i8\\'\\n    #pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=types, skip_header=1)\\n    \\n    with open(\"./pool_test_csv.csv\") as f:\\n        ncols = len(f.readline().split(\\',\\'))\\n    pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=None, skip_header=1, usecols=range(1,ncols))\\n    names = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=\\'<U12\\', skip_header=1, usecols=0)\\n    \\n    return pool, names\\n\\ndef load_database(filename):\\n    \\n    with open(filename,\\'rb\\') as file_object: \\n        db = pickle.load(file_object)\\n    return db\\n    \\ndef add_pool_to_database(pool, filename):\\n    \\n    db = load_database(filename)\\n    \\n    for name in pool.names:\\n        if name not in db[0]:\\n            new_id = max(db[1])+1\\n            db[0][name] = new_id\\n            db[1][new_id] = name\\n    \\n    db[2].append(pool)\\n    \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n    \\ndef initialize_database(filename):\\n    \\n    labels = [\\'fencer_to_id\\', \\'id_to_fencer\\', \\'pool_to_id\\', \\'id_to_pool\\', \\'pools\\', \\'fencers\\']\\n    db = ([{},{1000: \\'no student\\'},{}, {1000: \\'no pool\\'}, [], []], labels)\\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n        \\ndef construct_results_array_from_database(filename):\\n    \\n    db = load_database(filename)\\n    num_fencers = len(database[0])\\n    num_pools = len(database[2])\\n    \\n    results_array = np.zeros((num_pools, num_fencers+1, num_fencers+1), dtype=int)-1\\n    results_array[:,0,1:] = [*database[1].keys()][1:]\\n    results_array[:,1:,0] = [*database[1].keys()][1:]\\n    \\n    for i in range(len(database[2])):\\n        results_array[i,0,0] = database[2][i].ident\\n        results_array[i,1:num_fencers+1,1:num_fencers+1] = database[2][i].results\\n\\n    return results_array\\n    \\n\\n\\n        ',\n",
       "  'initialize_database(filename)',\n",
       "  \"with open(filename,'rb') as file_object: \\n    db = pickle.load(file_object)\",\n",
       "  'db[1]',\n",
       "  'db[1] = db[0]',\n",
       "  'db[1]',\n",
       "  'for i in range(len(db[1])):\\n    print(db[1][i])\\n    global db[1][i] = db[0][i]',\n",
       "  'for i in range(len(db[1])):\\n    print(db[1][i])\\n    globals()db[1][i] = db[0][i]',\n",
       "  'for i in range(len(db[1])):\\n    print(db[1][i])\\n    #globals()db[1][i] = db[0][i]',\n",
       "  'global db[1][0]',\n",
       "  'globals()db[1][0]',\n",
       "  'for i in range(len(db[1])):\\n    print(db[1][i])\\n    db[1][i] = db[0][i]',\n",
       "  'for i in range(len(db[1])):\\n    print(db[1][i])\\n    db[1][i] = db[0][i]',\n",
       "  'for i in range(len(db[1])):\\n    print(db[1][i])\\n    db[1][i] = db[0][i]',\n",
       "  'initialize_database(filename)',\n",
       "  \"with open(filename,'rb') as file_object: \\n    db = pickle.load(file_object)\",\n",
       "  'db',\n",
       "  'fencer_to_id',\n",
       "  'globals',\n",
       "  'globals()',\n",
       "  'globals()[fencer_to_id]',\n",
       "  \"with open(filename,'rb') as file_object: \\n    db = pickle.load(file_object)\",\n",
       "  'db',\n",
       "  'for i in range(len(db[1])):\\n    print(db[1][i])\\n    globals[db[1][i]: db[0][i]]',\n",
       "  'globals()[fencer_to_id]',\n",
       "  'globals()[fencer_to_id: 1]',\n",
       "  'globals()',\n",
       "  'globals()[str(fencer_to_id): 1]',\n",
       "  \"globals()['fencer_to_id': 1]\",\n",
       "  \"globals()['fencer_to_id'] = 1\",\n",
       "  'fencer_to_id',\n",
       "  'globals()[str(fencer_to_id)] = 1',\n",
       "  'fencer_to_id',\n",
       "  'globals()[str(fencer_to_id)] = 2',\n",
       "  'fencer_to_id',\n",
       "  'for i in range(len(db[1])):\\n    print(db[1][i])\\n    globals[db[1][i]] =db[0][i]',\n",
       "  \"with open(filename,'rb') as file_object: \\n    db = pickle.load(file_object)\",\n",
       "  'db',\n",
       "  'fencer_to_id',\n",
       "  'db[1]',\n",
       "  'db[1][0]',\n",
       "  'for i in range(len(db[1])):\\n    print(db[1][i])\\n    globals()[db[1][i]] = db[0][i]',\n",
       "  'fencer_to_d',\n",
       "  'fencer_to_id',\n",
       "  'id_to_fencer',\n",
       "  'locals()'],\n",
       " 'Out': {10: array([[[   1, 1001, 1002, 1003],\n",
       "          [1001,   -1,    5,    5],\n",
       "          [1002,    3,   -1,    5],\n",
       "          [1003,    1,    2,   -1]],\n",
       "  \n",
       "         [[   2, 1001, 1002, 1003],\n",
       "          [1001,   -1,    5,    5],\n",
       "          [1002,    3,   -1,    5],\n",
       "          [1003,    1,    2,   -1]],\n",
       "  \n",
       "         [[   3, 1001, 1002, 1003],\n",
       "          [1001,   -1,    5,    5],\n",
       "          [1002,    3,   -1,    5],\n",
       "          [1003,    1,    2,   -1]]]), 11: array([[1001,   -1,    5,    5],\n",
       "         [1001,   -1,    5,    5],\n",
       "         [1001,   -1,    5,    5]]), 18: 3, 22: [4, 5], 26: [(3, 4),\n",
       "   5], 27: (3,\n",
       "   4), 31: <function __main__.initialize_database>, 36: ([{},\n",
       "    {1000: 'no student'},\n",
       "    {},\n",
       "    {1000: 'no pool'},\n",
       "    [],\n",
       "    []], ('fencer_to_id',\n",
       "    'id_to_fencer',\n",
       "    'pool_to_id',\n",
       "    'id_to_pool',\n",
       "    'pools',\n",
       "    'fencers')), 37: [{},\n",
       "   {1000: 'no student'},\n",
       "   {},\n",
       "   {1000: 'no pool'},\n",
       "   [],\n",
       "   []], 38: ('fencer_to_id',\n",
       "   'id_to_fencer',\n",
       "   'pool_to_id',\n",
       "   'id_to_pool',\n",
       "   'pools',\n",
       "   'fencers'), 43: ('fencer_to_id',\n",
       "   'id_to_fencer',\n",
       "   'pool_to_id',\n",
       "   'id_to_pool',\n",
       "   'pools',\n",
       "   'fencers'), 45: ('fencer_to_id',\n",
       "   'id_to_fencer',\n",
       "   'pool_to_id',\n",
       "   'id_to_pool',\n",
       "   'pools',\n",
       "   'fencers'), 47: ('fencer_to_id',\n",
       "   'id_to_fencer',\n",
       "   'pool_to_id',\n",
       "   'id_to_pool',\n",
       "   'pools',\n",
       "   'fencers'), 51: [{},\n",
       "   {1000: 'no student'},\n",
       "   {},\n",
       "   {1000: 'no pool'},\n",
       "   [],\n",
       "   []], 53: [{},\n",
       "   {1000: 'no student'},\n",
       "   {},\n",
       "   {1000: 'no pool'},\n",
       "   [],\n",
       "   []], 64: ([{},\n",
       "    {1000: 'no student'},\n",
       "    {},\n",
       "    {1000: 'no pool'},\n",
       "    [],\n",
       "    []], ['fencer_to_id', 'id_to_fencer', 'pool_to_id', 'id_to_pool', 'pools', 'fencers']), 66: <function globals>, 67: {...}, 70: ([{},\n",
       "    {1000: 'no student'},\n",
       "    {},\n",
       "    {1000: 'no pool'},\n",
       "    [],\n",
       "    []],\n",
       "   ['fencer_to_id',\n",
       "    'id_to_fencer',\n",
       "    'pool_to_id',\n",
       "    'id_to_pool',\n",
       "    'pools',\n",
       "    'fencers']), 74: {...}, 78: 1, 80: 1, 82: 1, 85: ([{},\n",
       "    {1000: 'no student'},\n",
       "    {},\n",
       "    {1000: 'no pool'},\n",
       "    [],\n",
       "    []],\n",
       "   ['fencer_to_id',\n",
       "    'id_to_fencer',\n",
       "    'pool_to_id',\n",
       "    'id_to_pool',\n",
       "    'pools',\n",
       "    'fencers']), 86: 1, 87: ['fencer_to_id',\n",
       "   'id_to_fencer',\n",
       "   'pool_to_id',\n",
       "   'id_to_pool',\n",
       "   'pools',\n",
       "   'fencers'], 88: 'fencer_to_id', 91: {}, 92: {1000: 'no student'}},\n",
       " '_': {1000: 'no student'},\n",
       " '_10': array([[[   1, 1001, 1002, 1003],\n",
       "         [1001,   -1,    5,    5],\n",
       "         [1002,    3,   -1,    5],\n",
       "         [1003,    1,    2,   -1]],\n",
       " \n",
       "        [[   2, 1001, 1002, 1003],\n",
       "         [1001,   -1,    5,    5],\n",
       "         [1002,    3,   -1,    5],\n",
       "         [1003,    1,    2,   -1]],\n",
       " \n",
       "        [[   3, 1001, 1002, 1003],\n",
       "         [1001,   -1,    5,    5],\n",
       "         [1002,    3,   -1,    5],\n",
       "         [1003,    1,    2,   -1]]]),\n",
       " '_11': array([[1001,   -1,    5,    5],\n",
       "        [1001,   -1,    5,    5],\n",
       "        [1001,   -1,    5,    5]]),\n",
       " '_18': 3,\n",
       " '_22': [4, 5],\n",
       " '_26': [(3, 4), 5],\n",
       " '_27': (3, 4),\n",
       " '_31': <function __main__.initialize_database>,\n",
       " '_36': ([{}, {1000: 'no student'}, {}, {1000: 'no pool'}, [], []],\n",
       "  ('fencer_to_id',\n",
       "   'id_to_fencer',\n",
       "   'pool_to_id',\n",
       "   'id_to_pool',\n",
       "   'pools',\n",
       "   'fencers')),\n",
       " '_37': [{}, {1000: 'no student'}, {}, {1000: 'no pool'}, [], []],\n",
       " '_38': ('fencer_to_id',\n",
       "  'id_to_fencer',\n",
       "  'pool_to_id',\n",
       "  'id_to_pool',\n",
       "  'pools',\n",
       "  'fencers'),\n",
       " '_43': ('fencer_to_id',\n",
       "  'id_to_fencer',\n",
       "  'pool_to_id',\n",
       "  'id_to_pool',\n",
       "  'pools',\n",
       "  'fencers'),\n",
       " '_45': ('fencer_to_id',\n",
       "  'id_to_fencer',\n",
       "  'pool_to_id',\n",
       "  'id_to_pool',\n",
       "  'pools',\n",
       "  'fencers'),\n",
       " '_47': ('fencer_to_id',\n",
       "  'id_to_fencer',\n",
       "  'pool_to_id',\n",
       "  'id_to_pool',\n",
       "  'pools',\n",
       "  'fencers'),\n",
       " '_51': [{}, {1000: 'no student'}, {}, {1000: 'no pool'}, [], []],\n",
       " '_53': [{}, {1000: 'no student'}, {}, {1000: 'no pool'}, [], []],\n",
       " '_64': ([{}, {1000: 'no student'}, {}, {1000: 'no pool'}, [], []],\n",
       "  ['fencer_to_id',\n",
       "   'id_to_fencer',\n",
       "   'pool_to_id',\n",
       "   'id_to_pool',\n",
       "   'pools',\n",
       "   'fencers']),\n",
       " '_66': <function globals>,\n",
       " '_67': {...},\n",
       " '_70': ([{}, {1000: 'no student'}, {}, {1000: 'no pool'}, [], []],\n",
       "  ['fencer_to_id',\n",
       "   'id_to_fencer',\n",
       "   'pool_to_id',\n",
       "   'id_to_pool',\n",
       "   'pools',\n",
       "   'fencers']),\n",
       " '_74': {...},\n",
       " '_78': 1,\n",
       " '_80': 1,\n",
       " '_82': 1,\n",
       " '_85': ([{}, {1000: 'no student'}, {}, {1000: 'no pool'}, [], []],\n",
       "  ['fencer_to_id',\n",
       "   'id_to_fencer',\n",
       "   'pool_to_id',\n",
       "   'id_to_pool',\n",
       "   'pools',\n",
       "   'fencers']),\n",
       " '_86': 1,\n",
       " '_87': ['fencer_to_id',\n",
       "  'id_to_fencer',\n",
       "  'pool_to_id',\n",
       "  'id_to_pool',\n",
       "  'pools',\n",
       "  'fencers'],\n",
       " '_88': 'fencer_to_id',\n",
       " '_91': {},\n",
       " '_92': {1000: 'no student'},\n",
       " '__': {},\n",
       " '___': 'fencer_to_id',\n",
       " '__builtin__': <module 'builtins' (built-in)>,\n",
       " '__builtins__': <module 'builtins' (built-in)>,\n",
       " '__doc__': 'Automatically created module for IPython interactive environment',\n",
       " '__loader__': None,\n",
       " '__name__': '__main__',\n",
       " '__package__': None,\n",
       " '__spec__': None,\n",
       " '_dh': ['C:\\\\Users\\\\uskov_000\\\\fencing_project'],\n",
       " '_i': 'id_to_fencer',\n",
       " '_i1': 'results_array[results_array[:,0,:] == 1001]',\n",
       " '_i10': 'results_array',\n",
       " '_i11': 'results_array[results_array[:,0,:] == 1001]',\n",
       " '_i12': 'class FencingPool:\\n    \\n    def __init__(self, ident, imported):\\n        self.ident = ident\\n        self.date = str(datetime.date.today())\\n        self.results = imported[0]\\n        self.names = imported[1]\\n        \\n    def get_results(self):\\n        print(self.results)\\n        \\nclass Fencer:\\n    \\n    def __init__(self, ident, name):\\n        self.ident = ident\\n        self.name = name\\n        \\ndef pool_importer(pool_loc=\"./pool_test_csv.csv\"):\\n    \\n    #types = \\'<U12,i8,i8,i8\\'\\n    #pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=types, skip_header=1)\\n    \\n    with open(\"./pool_test_csv.csv\") as f:\\n        ncols = len(f.readline().split(\\',\\'))\\n    pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=None, skip_header=1, usecols=range(1,ncols))\\n    names = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=\\'<U12\\', skip_header=1, usecols=0)\\n    \\n    return pool, names\\n\\ndef load_database(filename):\\n    \\n    with open(filename,\\'rb\\') as file_object: \\n        db = pickle.load(file_object)\\n    return db\\n    \\ndef add_pool_to_database(pool, filename):\\n    \\n    db = load_database(filename)\\n    \\n    for name in pool.names:\\n        if name not in db[0]:\\n            new_id = max(db[1])+1\\n            db[0][name] = new_id\\n            db[1][new_id] = name\\n    \\n    db[2].append(pool)\\n    \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n    \\ndef initialize_database(filename):\\n    \\n    db = [{},{1000: \\'no student\\'},[]]    \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n        \\ndef construct_results_array_from_database(filename):\\n    \\n    db = load_database(filename)\\n    num_fencers = len(database[0])\\n    num_pools = len(database[2])\\n    \\n    results_array = np.zeros((num_pools, num_fencers+1, num_fencers+1), dtype=int)-1\\n    results_array[:,0,1:] = [*database[1].keys()][1:]\\n    results_array[:,1:,0] = [*database[1].keys()][1:]\\n    \\n    for i in range(len(database[2])):\\n        results_array[i,0,0] = database[2][i].ident\\n        results_array[i,1:num_fencers+1,1:num_fencers+1] = database[2][i].results\\n\\n    return results_array\\n    \\n\\n\\n        ',\n",
       " '_i13': 'x = 3',\n",
       " '_i14': \"pickle.dump(x, './test.log')\",\n",
       " '_i15': \"with open('./test.log', 'wb') as file_object:\\n        pickle.dump(db, file_object)\",\n",
       " '_i16': \"with open('./test.log', 'wb') as file_object:\\n        pickle.dump(x, file_object)\",\n",
       " '_i17': \"with open('./test.log','rb') as file_object: \\n    db = pickle.load(file_object)\",\n",
       " '_i18': 'db',\n",
       " '_i19': 'x = [4,5]',\n",
       " '_i2': 'import numpy as np\\nimport datetime\\nimport pickle\\n#import pandas as pd',\n",
       " '_i20': \"with open('./test.log', 'wb') as file_object:\\n        pickle.dump(x, file_object)\",\n",
       " '_i21': \"with open('./test.log','rb') as file_object: \\n    db = pickle.load(file_object)\",\n",
       " '_i22': 'db',\n",
       " '_i23': 'x = [(3,4),5]',\n",
       " '_i24': \"with open('./test.log', 'wb') as file_object:\\n        pickle.dump(x, file_object)\",\n",
       " '_i25': \"with open('./test.log','rb') as file_object: \\n    db = pickle.load(file_object)\",\n",
       " '_i26': 'db',\n",
       " '_i27': 'db[0]',\n",
       " '_i28': 'class FencingPool:\\n    \\n    def __init__(self, ident, imported):\\n        self.ident = ident\\n        self.date = str(datetime.date.today())\\n        self.results = imported[0]\\n        self.names = imported[1]\\n        \\n    def get_results(self):\\n        print(self.results)\\n        \\nclass Fencer:\\n    \\n    def __init__(self, ident, name):\\n        self.ident = ident\\n        self.name = name\\n        \\ndef pool_importer(pool_loc=\"./pool_test_csv.csv\"):\\n    \\n    #types = \\'<U12,i8,i8,i8\\'\\n    #pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=types, skip_header=1)\\n    \\n    with open(\"./pool_test_csv.csv\") as f:\\n        ncols = len(f.readline().split(\\',\\'))\\n    pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=None, skip_header=1, usecols=range(1,ncols))\\n    names = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=\\'<U12\\', skip_header=1, usecols=0)\\n    \\n    return pool, names\\n\\ndef load_database(filename):\\n    \\n    with open(filename,\\'rb\\') as file_object: \\n        db = pickle.load(file_object)\\n    return db\\n    \\ndef add_pool_to_database(pool, filename):\\n    \\n    db = load_database(filename)\\n    \\n    for name in pool.names:\\n        if name not in db[0]:\\n            new_id = max(db[1])+1\\n            db[0][name] = new_id\\n            db[1][new_id] = name\\n    \\n    db[2].append(pool)\\n    \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n    \\ndef initialize_database(filename):\\n    \\n    labels = (\\'fencer to id\\', \\'id to fencer\\', \\'pool to id\\', \\'id to pool\\', \\'pools\\', \\'fencers\\')\\n    db = [{},{1000: \\'no student\\'},{}, {1000: \\'no pool\\'}, [], []]   \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n        \\ndef construct_results_array_from_database(filename):\\n    \\n    db = load_database(filename)\\n    num_fencers = len(database[0])\\n    num_pools = len(database[2])\\n    \\n    results_array = np.zeros((num_pools, num_fencers+1, num_fencers+1), dtype=int)-1\\n    results_array[:,0,1:] = [*database[1].keys()][1:]\\n    results_array[:,1:,0] = [*database[1].keys()][1:]\\n    \\n    for i in range(len(database[2])):\\n        results_array[i,0,0] = database[2][i].ident\\n        results_array[i,1:num_fencers+1,1:num_fencers+1] = database[2][i].results\\n\\n    return results_array\\n    \\n\\n\\n        ',\n",
       " '_i29': 'class FencingPool:\\n    \\n    def __init__(self, ident, imported):\\n        self.ident = ident\\n        self.date = str(datetime.date.today())\\n        self.results = imported[0]\\n        self.names = imported[1]\\n        \\n    def get_results(self):\\n        print(self.results)\\n        \\nclass Fencer:\\n    \\n    def __init__(self, ident, name):\\n        self.ident = ident\\n        self.name = name\\n        \\ndef pool_importer(pool_loc=\"./pool_test_csv.csv\"):\\n    \\n    #types = \\'<U12,i8,i8,i8\\'\\n    #pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=types, skip_header=1)\\n    \\n    with open(\"./pool_test_csv.csv\") as f:\\n        ncols = len(f.readline().split(\\',\\'))\\n    pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=None, skip_header=1, usecols=range(1,ncols))\\n    names = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=\\'<U12\\', skip_header=1, usecols=0)\\n    \\n    return pool, names\\n\\ndef load_database(filename):\\n    \\n    with open(filename,\\'rb\\') as file_object: \\n        db = pickle.load(file_object)\\n    return db\\n    \\ndef add_pool_to_database(pool, filename):\\n    \\n    db = load_database(filename)\\n    \\n    for name in pool.names:\\n        if name not in db[0]:\\n            new_id = max(db[1])+1\\n            db[0][name] = new_id\\n            db[1][new_id] = name\\n    \\n    db[2].append(pool)\\n    \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n    \\ndef initialize_database(filename):\\n    \\n    labels = (\\'fencer to id\\', \\'id to fencer\\', \\'pool to id\\', \\'id to pool\\', \\'pools\\', \\'fencers\\')\\n    db = ([{},{1000: \\'no student\\'},{}, {1000: \\'no pool\\'}, [], []], labels)\\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n        \\ndef construct_results_array_from_database(filename):\\n    \\n    db = load_database(filename)\\n    num_fencers = len(database[0])\\n    num_pools = len(database[2])\\n    \\n    results_array = np.zeros((num_pools, num_fencers+1, num_fencers+1), dtype=int)-1\\n    results_array[:,0,1:] = [*database[1].keys()][1:]\\n    results_array[:,1:,0] = [*database[1].keys()][1:]\\n    \\n    for i in range(len(database[2])):\\n        results_array[i,0,0] = database[2][i].ident\\n        results_array[i,1:num_fencers+1,1:num_fencers+1] = database[2][i].results\\n\\n    return results_array\\n    \\n\\n\\n        ',\n",
       " '_i3': 'class FencingPool:\\n    \\n    def __init__(self, ident, imported):\\n        self.ident = ident\\n        self.date = str(datetime.date.today())\\n        self.results = imported[0]\\n        self.names = imported[1]\\n        \\n    def get_results(self):\\n        print(self.results)\\n        \\nclass Fencer:\\n    \\n    def __init__(self):\\n        \\n        \\ndef pool_importer(pool_loc=\"./pool_test_csv.csv\"):\\n    \\n    #types = \\'<U12,i8,i8,i8\\'\\n    #pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=types, skip_header=1)\\n    \\n    with open(\"./pool_test_csv.csv\") as f:\\n        ncols = len(f.readline().split(\\',\\'))\\n    pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=None, skip_header=1, usecols=range(1,ncols))\\n    names = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=\\'<U12\\', skip_header=1, usecols=0)\\n    \\n    return pool, names\\n\\ndef load_database(filename):\\n    \\n    with open(filename,\\'rb\\') as file_object: \\n        db = pickle.load(file_object)\\n    return db\\n    \\ndef add_pool_to_database(pool, filename):\\n    \\n    db = load_database(filename)\\n    \\n    for name in pool.names:\\n        if name not in db[0]:\\n            new_id = max(db[1])+1\\n            db[0][name] = new_id\\n            db[1][new_id] = name\\n    \\n    db[2].append(pool)\\n    \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n    \\ndef initialize_database(filename):\\n    \\n    db = [{},{1000: \\'no student\\'},[]]    \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n        \\ndef construct_results_array_from_database(filename):\\n    \\n    db = load_database(filename)\\n    num_fencers = len(database[0])\\n    num_pools = len(database[2])\\n    \\n    results_array = np.zeros((num_pools, num_fencers+1, num_fencers+1), dtype=int)-1\\n    results_array[:,0,1:] = [*database[1].keys()][1:]\\n    results_array[:,1:,0] = [*database[1].keys()][1:]\\n    \\n    for i in range(len(database[2])):\\n        results_array[i,0,0] = database[2][i].ident\\n        results_array[i,1:num_fencers+1,1:num_fencers+1] = database[2][i].results\\n\\n    return results_array\\n    \\n\\n\\n        ',\n",
       " '_i30': \"filename = 'data.log'\",\n",
       " '_i31': 'initialize_database',\n",
       " '_i32': 'initialize_database(filename)',\n",
       " '_i33': 'class FencingPool:\\n    \\n    def __init__(self, ident, imported):\\n        self.ident = ident\\n        self.date = str(datetime.date.today())\\n        self.results = imported[0]\\n        self.names = imported[1]\\n        \\n    def get_results(self):\\n        print(self.results)\\n        \\nclass Fencer:\\n    \\n    def __init__(self, ident, name):\\n        self.ident = ident\\n        self.name = name\\n        \\ndef pool_importer(pool_loc=\"./pool_test_csv.csv\"):\\n    \\n    #types = \\'<U12,i8,i8,i8\\'\\n    #pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=types, skip_header=1)\\n    \\n    with open(\"./pool_test_csv.csv\") as f:\\n        ncols = len(f.readline().split(\\',\\'))\\n    pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=None, skip_header=1, usecols=range(1,ncols))\\n    names = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=\\'<U12\\', skip_header=1, usecols=0)\\n    \\n    return pool, names\\n\\ndef load_database(filename):\\n    \\n    with open(filename,\\'rb\\') as file_object: \\n        db = pickle.load(file_object)\\n    return db\\n    \\ndef add_pool_to_database(pool, filename):\\n    \\n    db = load_database(filename)\\n    \\n    for name in pool.names:\\n        if name not in db[0]:\\n            new_id = max(db[1])+1\\n            db[0][name] = new_id\\n            db[1][new_id] = name\\n    \\n    db[2].append(pool)\\n    \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n    \\ndef initialize_database(filename):\\n    \\n    labels = (\\'fencer_to_id\\', \\'id_to_fencer\\', \\'pool_to_id\\', \\'id_to_pool\\', \\'pools\\', \\'fencers\\')\\n    db = ([{},{1000: \\'no student\\'},{}, {1000: \\'no pool\\'}, [], []], labels)\\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n        \\ndef construct_results_array_from_database(filename):\\n    \\n    db = load_database(filename)\\n    num_fencers = len(database[0])\\n    num_pools = len(database[2])\\n    \\n    results_array = np.zeros((num_pools, num_fencers+1, num_fencers+1), dtype=int)-1\\n    results_array[:,0,1:] = [*database[1].keys()][1:]\\n    results_array[:,1:,0] = [*database[1].keys()][1:]\\n    \\n    for i in range(len(database[2])):\\n        results_array[i,0,0] = database[2][i].ident\\n        results_array[i,1:num_fencers+1,1:num_fencers+1] = database[2][i].results\\n\\n    return results_array\\n    \\n\\n\\n        ',\n",
       " '_i34': 'initialize_database(filename)',\n",
       " '_i35': \"with open(filename,'rb') as file_object: \\n    db = pickle.load(file_object)\",\n",
       " '_i36': 'db',\n",
       " '_i37': 'db[0]',\n",
       " '_i38': 'db[1]',\n",
       " '_i39': 'for label in db[1]:\\n    print label',\n",
       " '_i4': 'class FencingPool:\\n    \\n    def __init__(self, ident, imported):\\n        self.ident = ident\\n        self.date = str(datetime.date.today())\\n        self.results = imported[0]\\n        self.names = imported[1]\\n        \\n    def get_results(self):\\n        print(self.results)\\n        \\n#class Fencer:\\n    \\n #   def __init__(self):\\n        \\n        \\ndef pool_importer(pool_loc=\"./pool_test_csv.csv\"):\\n    \\n    #types = \\'<U12,i8,i8,i8\\'\\n    #pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=types, skip_header=1)\\n    \\n    with open(\"./pool_test_csv.csv\") as f:\\n        ncols = len(f.readline().split(\\',\\'))\\n    pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=None, skip_header=1, usecols=range(1,ncols))\\n    names = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=\\'<U12\\', skip_header=1, usecols=0)\\n    \\n    return pool, names\\n\\ndef load_database(filename):\\n    \\n    with open(filename,\\'rb\\') as file_object: \\n        db = pickle.load(file_object)\\n    return db\\n    \\ndef add_pool_to_database(pool, filename):\\n    \\n    db = load_database(filename)\\n    \\n    for name in pool.names:\\n        if name not in db[0]:\\n            new_id = max(db[1])+1\\n            db[0][name] = new_id\\n            db[1][new_id] = name\\n    \\n    db[2].append(pool)\\n    \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n    \\ndef initialize_database(filename):\\n    \\n    db = [{},{1000: \\'no student\\'},[]]    \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n        \\ndef construct_results_array_from_database(filename):\\n    \\n    db = load_database(filename)\\n    num_fencers = len(database[0])\\n    num_pools = len(database[2])\\n    \\n    results_array = np.zeros((num_pools, num_fencers+1, num_fencers+1), dtype=int)-1\\n    results_array[:,0,1:] = [*database[1].keys()][1:]\\n    results_array[:,1:,0] = [*database[1].keys()][1:]\\n    \\n    for i in range(len(database[2])):\\n        results_array[i,0,0] = database[2][i].ident\\n        results_array[i,1:num_fencers+1,1:num_fencers+1] = database[2][i].results\\n\\n    return results_array\\n    \\n\\n\\n        ',\n",
       " '_i40': 'for label in db[1]:\\n    print(label)',\n",
       " '_i41': 'for i in range(len(db[1])):\\n    print(db[1][i])',\n",
       " '_i42': 'for i in range(len(db[1])):\\n    print(db[1][i])\\n    db[1][i] = db[0][i]',\n",
       " '_i43': 'db[1]',\n",
       " '_i44': 'db[1] = db[0]',\n",
       " '_i45': 'db[1]',\n",
       " '_i46': 'db[*1]',\n",
       " '_i47': 'db[1]',\n",
       " '_i48': 'class FencingPool:\\n    \\n    def __init__(self, ident, imported):\\n        self.ident = ident\\n        self.date = str(datetime.date.today())\\n        self.results = imported[0]\\n        self.names = imported[1]\\n        \\n    def get_results(self):\\n        print(self.results)\\n        \\nclass Fencer:\\n    \\n    def __init__(self, ident, name):\\n        self.ident = ident\\n        self.name = name\\n        \\ndef pool_importer(pool_loc=\"./pool_test_csv.csv\"):\\n    \\n    #types = \\'<U12,i8,i8,i8\\'\\n    #pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=types, skip_header=1)\\n    \\n    with open(\"./pool_test_csv.csv\") as f:\\n        ncols = len(f.readline().split(\\',\\'))\\n    pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=None, skip_header=1, usecols=range(1,ncols))\\n    names = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=\\'<U12\\', skip_header=1, usecols=0)\\n    \\n    return pool, names\\n\\ndef load_database(filename):\\n    \\n    with open(filename,\\'rb\\') as file_object: \\n        db = pickle.load(file_object)\\n    return db\\n    \\ndef add_pool_to_database(pool, filename):\\n    \\n    db = load_database(filename)\\n    \\n    for name in pool.names:\\n        if name not in db[0]:\\n            new_id = max(db[1])+1\\n            db[0][name] = new_id\\n            db[1][new_id] = name\\n    \\n    db[2].append(pool)\\n    \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n    \\ndef initialize_database(filename):\\n    \\n    labels = [\\'fencer_to_id\\', \\'id_to_fencer\\', \\'pool_to_id\\', \\'id_to_pool\\', \\'pools\\', \\'fencers\\']\\n    db = ([{},{1000: \\'no student\\'},{}, {1000: \\'no pool\\'}, [], []], labels)\\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n        \\ndef construct_results_array_from_database(filename):\\n    \\n    db = load_database(filename)\\n    num_fencers = len(database[0])\\n    num_pools = len(database[2])\\n    \\n    results_array = np.zeros((num_pools, num_fencers+1, num_fencers+1), dtype=int)-1\\n    results_array[:,0,1:] = [*database[1].keys()][1:]\\n    results_array[:,1:,0] = [*database[1].keys()][1:]\\n    \\n    for i in range(len(database[2])):\\n        results_array[i,0,0] = database[2][i].ident\\n        results_array[i,1:num_fencers+1,1:num_fencers+1] = database[2][i].results\\n\\n    return results_array\\n    \\n\\n\\n        ',\n",
       " '_i49': 'initialize_database(filename)',\n",
       " '_i5': 'pool1 = FencingPool(1, pool_importer())\\npool2 = FencingPool(2, pool_importer())\\npool3 = FencingPool(3, pool_importer())',\n",
       " '_i50': \"with open(filename,'rb') as file_object: \\n    db = pickle.load(file_object)\",\n",
       " '_i51': 'db[1]',\n",
       " '_i52': 'db[1] = db[0]',\n",
       " '_i53': 'db[1]',\n",
       " '_i54': 'for i in range(len(db[1])):\\n    print(db[1][i])\\n    global db[1][i] = db[0][i]',\n",
       " '_i55': 'for i in range(len(db[1])):\\n    print(db[1][i])\\n    globals()db[1][i] = db[0][i]',\n",
       " '_i56': 'for i in range(len(db[1])):\\n    print(db[1][i])\\n    #globals()db[1][i] = db[0][i]',\n",
       " '_i57': 'global db[1][0]',\n",
       " '_i58': 'globals()db[1][0]',\n",
       " '_i59': 'for i in range(len(db[1])):\\n    print(db[1][i])\\n    db[1][i] = db[0][i]',\n",
       " '_i6': \"filename = 'testfile'\",\n",
       " '_i60': 'for i in range(len(db[1])):\\n    print(db[1][i])\\n    db[1][i] = db[0][i]',\n",
       " '_i61': 'for i in range(len(db[1])):\\n    print(db[1][i])\\n    db[1][i] = db[0][i]',\n",
       " '_i62': 'initialize_database(filename)',\n",
       " '_i63': \"with open(filename,'rb') as file_object: \\n    db = pickle.load(file_object)\",\n",
       " '_i64': 'db',\n",
       " '_i65': 'fencer_to_id',\n",
       " '_i66': 'globals',\n",
       " '_i67': 'globals()',\n",
       " '_i68': 'globals()[fencer_to_id]',\n",
       " '_i69': \"with open(filename,'rb') as file_object: \\n    db = pickle.load(file_object)\",\n",
       " '_i7': 'initialize_database(filename)\\ndatabase = load_database(filename)\\nprint(database)',\n",
       " '_i70': 'db',\n",
       " '_i71': 'for i in range(len(db[1])):\\n    print(db[1][i])\\n    globals[db[1][i]: db[0][i]]',\n",
       " '_i72': 'globals()[fencer_to_id]',\n",
       " '_i73': 'globals()[fencer_to_id: 1]',\n",
       " '_i74': 'globals()',\n",
       " '_i75': 'globals()[str(fencer_to_id): 1]',\n",
       " '_i76': \"globals()['fencer_to_id': 1]\",\n",
       " '_i77': \"globals()['fencer_to_id'] = 1\",\n",
       " '_i78': 'fencer_to_id',\n",
       " '_i79': 'globals()[str(fencer_to_id)] = 1',\n",
       " '_i8': 'add_pool_to_database(pool1, filename)\\nadd_pool_to_database(pool2, filename)\\nadd_pool_to_database(pool3, filename)\\ndatabase = load_database(filename)\\nprint(database)',\n",
       " '_i80': 'fencer_to_id',\n",
       " '_i81': 'globals()[str(fencer_to_id)] = 2',\n",
       " '_i82': 'fencer_to_id',\n",
       " '_i83': 'for i in range(len(db[1])):\\n    print(db[1][i])\\n    globals[db[1][i]] =db[0][i]',\n",
       " '_i84': \"with open(filename,'rb') as file_object: \\n    db = pickle.load(file_object)\",\n",
       " '_i85': 'db',\n",
       " '_i86': 'fencer_to_id',\n",
       " '_i87': 'db[1]',\n",
       " '_i88': 'db[1][0]',\n",
       " '_i89': 'for i in range(len(db[1])):\\n    print(db[1][i])\\n    globals()[db[1][i]] = db[0][i]',\n",
       " '_i9': 'results_array = construct_results_array_from_database(filename)',\n",
       " '_i90': 'fencer_to_d',\n",
       " '_i91': 'fencer_to_id',\n",
       " '_i92': 'id_to_fencer',\n",
       " '_i93': 'locals()',\n",
       " '_ih': ['',\n",
       "  'results_array[results_array[:,0,:] == 1001]',\n",
       "  'import numpy as np\\nimport datetime\\nimport pickle\\n#import pandas as pd',\n",
       "  'class FencingPool:\\n    \\n    def __init__(self, ident, imported):\\n        self.ident = ident\\n        self.date = str(datetime.date.today())\\n        self.results = imported[0]\\n        self.names = imported[1]\\n        \\n    def get_results(self):\\n        print(self.results)\\n        \\nclass Fencer:\\n    \\n    def __init__(self):\\n        \\n        \\ndef pool_importer(pool_loc=\"./pool_test_csv.csv\"):\\n    \\n    #types = \\'<U12,i8,i8,i8\\'\\n    #pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=types, skip_header=1)\\n    \\n    with open(\"./pool_test_csv.csv\") as f:\\n        ncols = len(f.readline().split(\\',\\'))\\n    pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=None, skip_header=1, usecols=range(1,ncols))\\n    names = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=\\'<U12\\', skip_header=1, usecols=0)\\n    \\n    return pool, names\\n\\ndef load_database(filename):\\n    \\n    with open(filename,\\'rb\\') as file_object: \\n        db = pickle.load(file_object)\\n    return db\\n    \\ndef add_pool_to_database(pool, filename):\\n    \\n    db = load_database(filename)\\n    \\n    for name in pool.names:\\n        if name not in db[0]:\\n            new_id = max(db[1])+1\\n            db[0][name] = new_id\\n            db[1][new_id] = name\\n    \\n    db[2].append(pool)\\n    \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n    \\ndef initialize_database(filename):\\n    \\n    db = [{},{1000: \\'no student\\'},[]]    \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n        \\ndef construct_results_array_from_database(filename):\\n    \\n    db = load_database(filename)\\n    num_fencers = len(database[0])\\n    num_pools = len(database[2])\\n    \\n    results_array = np.zeros((num_pools, num_fencers+1, num_fencers+1), dtype=int)-1\\n    results_array[:,0,1:] = [*database[1].keys()][1:]\\n    results_array[:,1:,0] = [*database[1].keys()][1:]\\n    \\n    for i in range(len(database[2])):\\n        results_array[i,0,0] = database[2][i].ident\\n        results_array[i,1:num_fencers+1,1:num_fencers+1] = database[2][i].results\\n\\n    return results_array\\n    \\n\\n\\n        ',\n",
       "  'class FencingPool:\\n    \\n    def __init__(self, ident, imported):\\n        self.ident = ident\\n        self.date = str(datetime.date.today())\\n        self.results = imported[0]\\n        self.names = imported[1]\\n        \\n    def get_results(self):\\n        print(self.results)\\n        \\n#class Fencer:\\n    \\n #   def __init__(self):\\n        \\n        \\ndef pool_importer(pool_loc=\"./pool_test_csv.csv\"):\\n    \\n    #types = \\'<U12,i8,i8,i8\\'\\n    #pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=types, skip_header=1)\\n    \\n    with open(\"./pool_test_csv.csv\") as f:\\n        ncols = len(f.readline().split(\\',\\'))\\n    pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=None, skip_header=1, usecols=range(1,ncols))\\n    names = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=\\'<U12\\', skip_header=1, usecols=0)\\n    \\n    return pool, names\\n\\ndef load_database(filename):\\n    \\n    with open(filename,\\'rb\\') as file_object: \\n        db = pickle.load(file_object)\\n    return db\\n    \\ndef add_pool_to_database(pool, filename):\\n    \\n    db = load_database(filename)\\n    \\n    for name in pool.names:\\n        if name not in db[0]:\\n            new_id = max(db[1])+1\\n            db[0][name] = new_id\\n            db[1][new_id] = name\\n    \\n    db[2].append(pool)\\n    \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n    \\ndef initialize_database(filename):\\n    \\n    db = [{},{1000: \\'no student\\'},[]]    \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n        \\ndef construct_results_array_from_database(filename):\\n    \\n    db = load_database(filename)\\n    num_fencers = len(database[0])\\n    num_pools = len(database[2])\\n    \\n    results_array = np.zeros((num_pools, num_fencers+1, num_fencers+1), dtype=int)-1\\n    results_array[:,0,1:] = [*database[1].keys()][1:]\\n    results_array[:,1:,0] = [*database[1].keys()][1:]\\n    \\n    for i in range(len(database[2])):\\n        results_array[i,0,0] = database[2][i].ident\\n        results_array[i,1:num_fencers+1,1:num_fencers+1] = database[2][i].results\\n\\n    return results_array\\n    \\n\\n\\n        ',\n",
       "  'pool1 = FencingPool(1, pool_importer())\\npool2 = FencingPool(2, pool_importer())\\npool3 = FencingPool(3, pool_importer())',\n",
       "  \"filename = 'testfile'\",\n",
       "  'initialize_database(filename)\\ndatabase = load_database(filename)\\nprint(database)',\n",
       "  'add_pool_to_database(pool1, filename)\\nadd_pool_to_database(pool2, filename)\\nadd_pool_to_database(pool3, filename)\\ndatabase = load_database(filename)\\nprint(database)',\n",
       "  'results_array = construct_results_array_from_database(filename)',\n",
       "  'results_array',\n",
       "  'results_array[results_array[:,0,:] == 1001]',\n",
       "  'class FencingPool:\\n    \\n    def __init__(self, ident, imported):\\n        self.ident = ident\\n        self.date = str(datetime.date.today())\\n        self.results = imported[0]\\n        self.names = imported[1]\\n        \\n    def get_results(self):\\n        print(self.results)\\n        \\nclass Fencer:\\n    \\n    def __init__(self, ident, name):\\n        self.ident = ident\\n        self.name = name\\n        \\ndef pool_importer(pool_loc=\"./pool_test_csv.csv\"):\\n    \\n    #types = \\'<U12,i8,i8,i8\\'\\n    #pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=types, skip_header=1)\\n    \\n    with open(\"./pool_test_csv.csv\") as f:\\n        ncols = len(f.readline().split(\\',\\'))\\n    pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=None, skip_header=1, usecols=range(1,ncols))\\n    names = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=\\'<U12\\', skip_header=1, usecols=0)\\n    \\n    return pool, names\\n\\ndef load_database(filename):\\n    \\n    with open(filename,\\'rb\\') as file_object: \\n        db = pickle.load(file_object)\\n    return db\\n    \\ndef add_pool_to_database(pool, filename):\\n    \\n    db = load_database(filename)\\n    \\n    for name in pool.names:\\n        if name not in db[0]:\\n            new_id = max(db[1])+1\\n            db[0][name] = new_id\\n            db[1][new_id] = name\\n    \\n    db[2].append(pool)\\n    \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n    \\ndef initialize_database(filename):\\n    \\n    db = [{},{1000: \\'no student\\'},[]]    \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n        \\ndef construct_results_array_from_database(filename):\\n    \\n    db = load_database(filename)\\n    num_fencers = len(database[0])\\n    num_pools = len(database[2])\\n    \\n    results_array = np.zeros((num_pools, num_fencers+1, num_fencers+1), dtype=int)-1\\n    results_array[:,0,1:] = [*database[1].keys()][1:]\\n    results_array[:,1:,0] = [*database[1].keys()][1:]\\n    \\n    for i in range(len(database[2])):\\n        results_array[i,0,0] = database[2][i].ident\\n        results_array[i,1:num_fencers+1,1:num_fencers+1] = database[2][i].results\\n\\n    return results_array\\n    \\n\\n\\n        ',\n",
       "  'x = 3',\n",
       "  \"pickle.dump(x, './test.log')\",\n",
       "  \"with open('./test.log', 'wb') as file_object:\\n        pickle.dump(db, file_object)\",\n",
       "  \"with open('./test.log', 'wb') as file_object:\\n        pickle.dump(x, file_object)\",\n",
       "  \"with open('./test.log','rb') as file_object: \\n    db = pickle.load(file_object)\",\n",
       "  'db',\n",
       "  'x = [4,5]',\n",
       "  \"with open('./test.log', 'wb') as file_object:\\n        pickle.dump(x, file_object)\",\n",
       "  \"with open('./test.log','rb') as file_object: \\n    db = pickle.load(file_object)\",\n",
       "  'db',\n",
       "  'x = [(3,4),5]',\n",
       "  \"with open('./test.log', 'wb') as file_object:\\n        pickle.dump(x, file_object)\",\n",
       "  \"with open('./test.log','rb') as file_object: \\n    db = pickle.load(file_object)\",\n",
       "  'db',\n",
       "  'db[0]',\n",
       "  'class FencingPool:\\n    \\n    def __init__(self, ident, imported):\\n        self.ident = ident\\n        self.date = str(datetime.date.today())\\n        self.results = imported[0]\\n        self.names = imported[1]\\n        \\n    def get_results(self):\\n        print(self.results)\\n        \\nclass Fencer:\\n    \\n    def __init__(self, ident, name):\\n        self.ident = ident\\n        self.name = name\\n        \\ndef pool_importer(pool_loc=\"./pool_test_csv.csv\"):\\n    \\n    #types = \\'<U12,i8,i8,i8\\'\\n    #pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=types, skip_header=1)\\n    \\n    with open(\"./pool_test_csv.csv\") as f:\\n        ncols = len(f.readline().split(\\',\\'))\\n    pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=None, skip_header=1, usecols=range(1,ncols))\\n    names = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=\\'<U12\\', skip_header=1, usecols=0)\\n    \\n    return pool, names\\n\\ndef load_database(filename):\\n    \\n    with open(filename,\\'rb\\') as file_object: \\n        db = pickle.load(file_object)\\n    return db\\n    \\ndef add_pool_to_database(pool, filename):\\n    \\n    db = load_database(filename)\\n    \\n    for name in pool.names:\\n        if name not in db[0]:\\n            new_id = max(db[1])+1\\n            db[0][name] = new_id\\n            db[1][new_id] = name\\n    \\n    db[2].append(pool)\\n    \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n    \\ndef initialize_database(filename):\\n    \\n    labels = (\\'fencer to id\\', \\'id to fencer\\', \\'pool to id\\', \\'id to pool\\', \\'pools\\', \\'fencers\\')\\n    db = [{},{1000: \\'no student\\'},{}, {1000: \\'no pool\\'}, [], []]   \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n        \\ndef construct_results_array_from_database(filename):\\n    \\n    db = load_database(filename)\\n    num_fencers = len(database[0])\\n    num_pools = len(database[2])\\n    \\n    results_array = np.zeros((num_pools, num_fencers+1, num_fencers+1), dtype=int)-1\\n    results_array[:,0,1:] = [*database[1].keys()][1:]\\n    results_array[:,1:,0] = [*database[1].keys()][1:]\\n    \\n    for i in range(len(database[2])):\\n        results_array[i,0,0] = database[2][i].ident\\n        results_array[i,1:num_fencers+1,1:num_fencers+1] = database[2][i].results\\n\\n    return results_array\\n    \\n\\n\\n        ',\n",
       "  'class FencingPool:\\n    \\n    def __init__(self, ident, imported):\\n        self.ident = ident\\n        self.date = str(datetime.date.today())\\n        self.results = imported[0]\\n        self.names = imported[1]\\n        \\n    def get_results(self):\\n        print(self.results)\\n        \\nclass Fencer:\\n    \\n    def __init__(self, ident, name):\\n        self.ident = ident\\n        self.name = name\\n        \\ndef pool_importer(pool_loc=\"./pool_test_csv.csv\"):\\n    \\n    #types = \\'<U12,i8,i8,i8\\'\\n    #pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=types, skip_header=1)\\n    \\n    with open(\"./pool_test_csv.csv\") as f:\\n        ncols = len(f.readline().split(\\',\\'))\\n    pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=None, skip_header=1, usecols=range(1,ncols))\\n    names = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=\\'<U12\\', skip_header=1, usecols=0)\\n    \\n    return pool, names\\n\\ndef load_database(filename):\\n    \\n    with open(filename,\\'rb\\') as file_object: \\n        db = pickle.load(file_object)\\n    return db\\n    \\ndef add_pool_to_database(pool, filename):\\n    \\n    db = load_database(filename)\\n    \\n    for name in pool.names:\\n        if name not in db[0]:\\n            new_id = max(db[1])+1\\n            db[0][name] = new_id\\n            db[1][new_id] = name\\n    \\n    db[2].append(pool)\\n    \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n    \\ndef initialize_database(filename):\\n    \\n    labels = (\\'fencer to id\\', \\'id to fencer\\', \\'pool to id\\', \\'id to pool\\', \\'pools\\', \\'fencers\\')\\n    db = ([{},{1000: \\'no student\\'},{}, {1000: \\'no pool\\'}, [], []], labels)\\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n        \\ndef construct_results_array_from_database(filename):\\n    \\n    db = load_database(filename)\\n    num_fencers = len(database[0])\\n    num_pools = len(database[2])\\n    \\n    results_array = np.zeros((num_pools, num_fencers+1, num_fencers+1), dtype=int)-1\\n    results_array[:,0,1:] = [*database[1].keys()][1:]\\n    results_array[:,1:,0] = [*database[1].keys()][1:]\\n    \\n    for i in range(len(database[2])):\\n        results_array[i,0,0] = database[2][i].ident\\n        results_array[i,1:num_fencers+1,1:num_fencers+1] = database[2][i].results\\n\\n    return results_array\\n    \\n\\n\\n        ',\n",
       "  \"filename = 'data.log'\",\n",
       "  'initialize_database',\n",
       "  'initialize_database(filename)',\n",
       "  'class FencingPool:\\n    \\n    def __init__(self, ident, imported):\\n        self.ident = ident\\n        self.date = str(datetime.date.today())\\n        self.results = imported[0]\\n        self.names = imported[1]\\n        \\n    def get_results(self):\\n        print(self.results)\\n        \\nclass Fencer:\\n    \\n    def __init__(self, ident, name):\\n        self.ident = ident\\n        self.name = name\\n        \\ndef pool_importer(pool_loc=\"./pool_test_csv.csv\"):\\n    \\n    #types = \\'<U12,i8,i8,i8\\'\\n    #pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=types, skip_header=1)\\n    \\n    with open(\"./pool_test_csv.csv\") as f:\\n        ncols = len(f.readline().split(\\',\\'))\\n    pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=None, skip_header=1, usecols=range(1,ncols))\\n    names = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=\\'<U12\\', skip_header=1, usecols=0)\\n    \\n    return pool, names\\n\\ndef load_database(filename):\\n    \\n    with open(filename,\\'rb\\') as file_object: \\n        db = pickle.load(file_object)\\n    return db\\n    \\ndef add_pool_to_database(pool, filename):\\n    \\n    db = load_database(filename)\\n    \\n    for name in pool.names:\\n        if name not in db[0]:\\n            new_id = max(db[1])+1\\n            db[0][name] = new_id\\n            db[1][new_id] = name\\n    \\n    db[2].append(pool)\\n    \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n    \\ndef initialize_database(filename):\\n    \\n    labels = (\\'fencer_to_id\\', \\'id_to_fencer\\', \\'pool_to_id\\', \\'id_to_pool\\', \\'pools\\', \\'fencers\\')\\n    db = ([{},{1000: \\'no student\\'},{}, {1000: \\'no pool\\'}, [], []], labels)\\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n        \\ndef construct_results_array_from_database(filename):\\n    \\n    db = load_database(filename)\\n    num_fencers = len(database[0])\\n    num_pools = len(database[2])\\n    \\n    results_array = np.zeros((num_pools, num_fencers+1, num_fencers+1), dtype=int)-1\\n    results_array[:,0,1:] = [*database[1].keys()][1:]\\n    results_array[:,1:,0] = [*database[1].keys()][1:]\\n    \\n    for i in range(len(database[2])):\\n        results_array[i,0,0] = database[2][i].ident\\n        results_array[i,1:num_fencers+1,1:num_fencers+1] = database[2][i].results\\n\\n    return results_array\\n    \\n\\n\\n        ',\n",
       "  'initialize_database(filename)',\n",
       "  \"with open(filename,'rb') as file_object: \\n    db = pickle.load(file_object)\",\n",
       "  'db',\n",
       "  'db[0]',\n",
       "  'db[1]',\n",
       "  'for label in db[1]:\\n    print label',\n",
       "  'for label in db[1]:\\n    print(label)',\n",
       "  'for i in range(len(db[1])):\\n    print(db[1][i])',\n",
       "  'for i in range(len(db[1])):\\n    print(db[1][i])\\n    db[1][i] = db[0][i]',\n",
       "  'db[1]',\n",
       "  'db[1] = db[0]',\n",
       "  'db[1]',\n",
       "  'db[*1]',\n",
       "  'db[1]',\n",
       "  'class FencingPool:\\n    \\n    def __init__(self, ident, imported):\\n        self.ident = ident\\n        self.date = str(datetime.date.today())\\n        self.results = imported[0]\\n        self.names = imported[1]\\n        \\n    def get_results(self):\\n        print(self.results)\\n        \\nclass Fencer:\\n    \\n    def __init__(self, ident, name):\\n        self.ident = ident\\n        self.name = name\\n        \\ndef pool_importer(pool_loc=\"./pool_test_csv.csv\"):\\n    \\n    #types = \\'<U12,i8,i8,i8\\'\\n    #pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=types, skip_header=1)\\n    \\n    with open(\"./pool_test_csv.csv\") as f:\\n        ncols = len(f.readline().split(\\',\\'))\\n    pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=None, skip_header=1, usecols=range(1,ncols))\\n    names = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=\\',\\', dtype=\\'<U12\\', skip_header=1, usecols=0)\\n    \\n    return pool, names\\n\\ndef load_database(filename):\\n    \\n    with open(filename,\\'rb\\') as file_object: \\n        db = pickle.load(file_object)\\n    return db\\n    \\ndef add_pool_to_database(pool, filename):\\n    \\n    db = load_database(filename)\\n    \\n    for name in pool.names:\\n        if name not in db[0]:\\n            new_id = max(db[1])+1\\n            db[0][name] = new_id\\n            db[1][new_id] = name\\n    \\n    db[2].append(pool)\\n    \\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n    \\ndef initialize_database(filename):\\n    \\n    labels = [\\'fencer_to_id\\', \\'id_to_fencer\\', \\'pool_to_id\\', \\'id_to_pool\\', \\'pools\\', \\'fencers\\']\\n    db = ([{},{1000: \\'no student\\'},{}, {1000: \\'no pool\\'}, [], []], labels)\\n    with open(filename, \\'wb\\') as file_object:\\n        pickle.dump(db, file_object)\\n        \\ndef construct_results_array_from_database(filename):\\n    \\n    db = load_database(filename)\\n    num_fencers = len(database[0])\\n    num_pools = len(database[2])\\n    \\n    results_array = np.zeros((num_pools, num_fencers+1, num_fencers+1), dtype=int)-1\\n    results_array[:,0,1:] = [*database[1].keys()][1:]\\n    results_array[:,1:,0] = [*database[1].keys()][1:]\\n    \\n    for i in range(len(database[2])):\\n        results_array[i,0,0] = database[2][i].ident\\n        results_array[i,1:num_fencers+1,1:num_fencers+1] = database[2][i].results\\n\\n    return results_array\\n    \\n\\n\\n        ',\n",
       "  'initialize_database(filename)',\n",
       "  \"with open(filename,'rb') as file_object: \\n    db = pickle.load(file_object)\",\n",
       "  'db[1]',\n",
       "  'db[1] = db[0]',\n",
       "  'db[1]',\n",
       "  'for i in range(len(db[1])):\\n    print(db[1][i])\\n    global db[1][i] = db[0][i]',\n",
       "  'for i in range(len(db[1])):\\n    print(db[1][i])\\n    globals()db[1][i] = db[0][i]',\n",
       "  'for i in range(len(db[1])):\\n    print(db[1][i])\\n    #globals()db[1][i] = db[0][i]',\n",
       "  'global db[1][0]',\n",
       "  'globals()db[1][0]',\n",
       "  'for i in range(len(db[1])):\\n    print(db[1][i])\\n    db[1][i] = db[0][i]',\n",
       "  'for i in range(len(db[1])):\\n    print(db[1][i])\\n    db[1][i] = db[0][i]',\n",
       "  'for i in range(len(db[1])):\\n    print(db[1][i])\\n    db[1][i] = db[0][i]',\n",
       "  'initialize_database(filename)',\n",
       "  \"with open(filename,'rb') as file_object: \\n    db = pickle.load(file_object)\",\n",
       "  'db',\n",
       "  'fencer_to_id',\n",
       "  'globals',\n",
       "  'globals()',\n",
       "  'globals()[fencer_to_id]',\n",
       "  \"with open(filename,'rb') as file_object: \\n    db = pickle.load(file_object)\",\n",
       "  'db',\n",
       "  'for i in range(len(db[1])):\\n    print(db[1][i])\\n    globals[db[1][i]: db[0][i]]',\n",
       "  'globals()[fencer_to_id]',\n",
       "  'globals()[fencer_to_id: 1]',\n",
       "  'globals()',\n",
       "  'globals()[str(fencer_to_id): 1]',\n",
       "  \"globals()['fencer_to_id': 1]\",\n",
       "  \"globals()['fencer_to_id'] = 1\",\n",
       "  'fencer_to_id',\n",
       "  'globals()[str(fencer_to_id)] = 1',\n",
       "  'fencer_to_id',\n",
       "  'globals()[str(fencer_to_id)] = 2',\n",
       "  'fencer_to_id',\n",
       "  'for i in range(len(db[1])):\\n    print(db[1][i])\\n    globals[db[1][i]] =db[0][i]',\n",
       "  \"with open(filename,'rb') as file_object: \\n    db = pickle.load(file_object)\",\n",
       "  'db',\n",
       "  'fencer_to_id',\n",
       "  'db[1]',\n",
       "  'db[1][0]',\n",
       "  'for i in range(len(db[1])):\\n    print(db[1][i])\\n    globals()[db[1][i]] = db[0][i]',\n",
       "  'fencer_to_d',\n",
       "  'fencer_to_id',\n",
       "  'id_to_fencer',\n",
       "  'locals()'],\n",
       " '_ii': 'fencer_to_id',\n",
       " '_iii': 'fencer_to_d',\n",
       " '_oh': {10: array([[[   1, 1001, 1002, 1003],\n",
       "          [1001,   -1,    5,    5],\n",
       "          [1002,    3,   -1,    5],\n",
       "          [1003,    1,    2,   -1]],\n",
       "  \n",
       "         [[   2, 1001, 1002, 1003],\n",
       "          [1001,   -1,    5,    5],\n",
       "          [1002,    3,   -1,    5],\n",
       "          [1003,    1,    2,   -1]],\n",
       "  \n",
       "         [[   3, 1001, 1002, 1003],\n",
       "          [1001,   -1,    5,    5],\n",
       "          [1002,    3,   -1,    5],\n",
       "          [1003,    1,    2,   -1]]]), 11: array([[1001,   -1,    5,    5],\n",
       "         [1001,   -1,    5,    5],\n",
       "         [1001,   -1,    5,    5]]), 18: 3, 22: [4, 5], 26: [(3, 4),\n",
       "   5], 27: (3,\n",
       "   4), 31: <function __main__.initialize_database>, 36: ([{},\n",
       "    {1000: 'no student'},\n",
       "    {},\n",
       "    {1000: 'no pool'},\n",
       "    [],\n",
       "    []], ('fencer_to_id',\n",
       "    'id_to_fencer',\n",
       "    'pool_to_id',\n",
       "    'id_to_pool',\n",
       "    'pools',\n",
       "    'fencers')), 37: [{},\n",
       "   {1000: 'no student'},\n",
       "   {},\n",
       "   {1000: 'no pool'},\n",
       "   [],\n",
       "   []], 38: ('fencer_to_id',\n",
       "   'id_to_fencer',\n",
       "   'pool_to_id',\n",
       "   'id_to_pool',\n",
       "   'pools',\n",
       "   'fencers'), 43: ('fencer_to_id',\n",
       "   'id_to_fencer',\n",
       "   'pool_to_id',\n",
       "   'id_to_pool',\n",
       "   'pools',\n",
       "   'fencers'), 45: ('fencer_to_id',\n",
       "   'id_to_fencer',\n",
       "   'pool_to_id',\n",
       "   'id_to_pool',\n",
       "   'pools',\n",
       "   'fencers'), 47: ('fencer_to_id',\n",
       "   'id_to_fencer',\n",
       "   'pool_to_id',\n",
       "   'id_to_pool',\n",
       "   'pools',\n",
       "   'fencers'), 51: [{},\n",
       "   {1000: 'no student'},\n",
       "   {},\n",
       "   {1000: 'no pool'},\n",
       "   [],\n",
       "   []], 53: [{},\n",
       "   {1000: 'no student'},\n",
       "   {},\n",
       "   {1000: 'no pool'},\n",
       "   [],\n",
       "   []], 64: ([{},\n",
       "    {1000: 'no student'},\n",
       "    {},\n",
       "    {1000: 'no pool'},\n",
       "    [],\n",
       "    []], ['fencer_to_id', 'id_to_fencer', 'pool_to_id', 'id_to_pool', 'pools', 'fencers']), 66: <function globals>, 67: {...}, 70: ([{},\n",
       "    {1000: 'no student'},\n",
       "    {},\n",
       "    {1000: 'no pool'},\n",
       "    [],\n",
       "    []],\n",
       "   ['fencer_to_id',\n",
       "    'id_to_fencer',\n",
       "    'pool_to_id',\n",
       "    'id_to_pool',\n",
       "    'pools',\n",
       "    'fencers']), 74: {...}, 78: 1, 80: 1, 82: 1, 85: ([{},\n",
       "    {1000: 'no student'},\n",
       "    {},\n",
       "    {1000: 'no pool'},\n",
       "    [],\n",
       "    []],\n",
       "   ['fencer_to_id',\n",
       "    'id_to_fencer',\n",
       "    'pool_to_id',\n",
       "    'id_to_pool',\n",
       "    'pools',\n",
       "    'fencers']), 86: 1, 87: ['fencer_to_id',\n",
       "   'id_to_fencer',\n",
       "   'pool_to_id',\n",
       "   'id_to_pool',\n",
       "   'pools',\n",
       "   'fencers'], 88: 'fencer_to_id', 91: {}, 92: {1000: 'no student'}},\n",
       " '_sh': <module 'IPython.core.shadowns' from 'C:\\\\Users\\\\uskov_000\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\shadowns.py'>,\n",
       " 'add_pool_to_database': <function __main__.add_pool_to_database>,\n",
       " 'construct_results_array_from_database': <function __main__.construct_results_array_from_database>,\n",
       " 'database': [{'Alice': 1001, 'Bob': 1002, 'Chuck': 1003},\n",
       "  {1000: 'no student', 1001: 'Alice', 1002: 'Bob', 1003: 'Chuck'},\n",
       "  [<__main__.FencingPool at 0x1cd71628630>,\n",
       "   <__main__.FencingPool at 0x1cd71628898>,\n",
       "   <__main__.FencingPool at 0x1cd71628940>]],\n",
       " 'datetime': <module 'datetime' from 'C:\\\\Users\\\\uskov_000\\\\Anaconda3\\\\lib\\\\datetime.py'>,\n",
       " 'db': ([{}, {1000: 'no student'}, {}, {1000: 'no pool'}, [], []],\n",
       "  ['fencer_to_id',\n",
       "   'id_to_fencer',\n",
       "   'pool_to_id',\n",
       "   'id_to_pool',\n",
       "   'pools',\n",
       "   'fencers']),\n",
       " 'exit': <IPython.core.autocall.ZMQExitAutocall at 0x1cd6ffd28d0>,\n",
       " 'fencer_to_id': {},\n",
       " 'fencers': [],\n",
       " 'file_object': <_io.BufferedReader name='data.log'>,\n",
       " 'filename': 'data.log',\n",
       " 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x000001CD6FF90048>>,\n",
       " 'i': 5,\n",
       " 'id_to_fencer': {1000: 'no student'},\n",
       " 'id_to_pool': {1000: 'no pool'},\n",
       " 'initialize_database': <function __main__.initialize_database>,\n",
       " 'label': 'fencers',\n",
       " 'load_database': <function __main__.load_database>,\n",
       " 'np': <module 'numpy' from 'C:\\\\Users\\\\uskov_000\\\\Anaconda3\\\\lib\\\\site-packages\\\\numpy\\\\__init__.py'>,\n",
       " 'pickle': <module 'pickle' from 'C:\\\\Users\\\\uskov_000\\\\Anaconda3\\\\lib\\\\pickle.py'>,\n",
       " 'pool1': <__main__.FencingPool at 0x1cd71553a20>,\n",
       " 'pool2': <__main__.FencingPool at 0x1cd71559208>,\n",
       " 'pool3': <__main__.FencingPool at 0x1cd71561e80>,\n",
       " 'pool_importer': <function __main__.pool_importer>,\n",
       " 'pool_to_id': {},\n",
       " 'pools': [],\n",
       " 'quit': <IPython.core.autocall.ZMQExitAutocall at 0x1cd6ffd28d0>,\n",
       " 'results_array': array([[[   1, 1001, 1002, 1003],\n",
       "         [1001,   -1,    5,    5],\n",
       "         [1002,    3,   -1,    5],\n",
       "         [1003,    1,    2,   -1]],\n",
       " \n",
       "        [[   2, 1001, 1002, 1003],\n",
       "         [1001,   -1,    5,    5],\n",
       "         [1002,    3,   -1,    5],\n",
       "         [1003,    1,    2,   -1]],\n",
       " \n",
       "        [[   3, 1001, 1002, 1003],\n",
       "         [1001,   -1,    5,    5],\n",
       "         [1002,    3,   -1,    5],\n",
       "         [1003,    1,    2,   -1]]]),\n",
       " 'x': [(3, 4), 5]}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1000: 'no student'}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_fencer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_array = construct_results_array_from_database(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[   1, 1001, 1002, 1003],\n",
       "        [1001,   -1,    5,    5],\n",
       "        [1002,    3,   -1,    5],\n",
       "        [1003,    1,    2,   -1]],\n",
       "\n",
       "       [[   2, 1001, 1002, 1003],\n",
       "        [1001,   -1,    5,    5],\n",
       "        [1002,    3,   -1,    5],\n",
       "        [1003,    1,    2,   -1]],\n",
       "\n",
       "       [[   3, 1001, 1002, 1003],\n",
       "        [1001,   -1,    5,    5],\n",
       "        [1002,    3,   -1,    5],\n",
       "        [1003,    1,    2,   -1]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1001,   -1,    5,    5],\n",
       "       [1001,   -1,    5,    5],\n",
       "       [1001,   -1,    5,    5]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_array[results_array[:,0,:] == 1001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  -1, 1001, 1002, 1003],\n",
       "        [1001,   -1,   -1,   -1],\n",
       "        [1002,   -1,   -1,   -1],\n",
       "        [1003,   -1,   -1,   -1]],\n",
       "\n",
       "       [[  -1, 1001, 1002, 1003],\n",
       "        [1001,   -1,   -1,   -1],\n",
       "        [1002,   -1,   -1,   -1],\n",
       "        [1003,   -1,   -1,   -1]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.zeros((num_pools, num_fencers+1, num_fencers+1), dtype=int)-1\n",
    "p[:,0,1:] = [*database[1].keys()][1:]\n",
    "p[:,1:,0] = [*database[1].keys()][1:]\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  -1, 1001, 1002, 1003],\n",
       "        [1001,   -1,    5,    5],\n",
       "        [1002,    3,   -1,    5],\n",
       "        [1003,    1,    2,   -1]],\n",
       "\n",
       "       [[  -1, 1001, 1002, 1003],\n",
       "        [1001,   -1,   -1,   -1],\n",
       "        [1002,   -1,   -1,   -1],\n",
       "        [1003,   -1,   -1,   -1]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[0,1:num_fencers+1,1:num_fencers+1] = database[2][0].results\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(database[2])):\n",
    "    \n",
    "    p[i,1:num_fencers+1,1:num_fencers+1] = database[2][i].results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  -1, 1001, 1002, 1003],\n",
       "        [1001,   -1,    5,    5],\n",
       "        [1002,    3,   -1,    5],\n",
       "        [1003,    1,    2,   -1]],\n",
       "\n",
       "       [[  -1, 1001, 1002, 1003],\n",
       "        [1001,   -1,    5,    5],\n",
       "        [1002,    3,   -1,    5],\n",
       "        [1003,    1,    2,   -1]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1', '2'],\n",
       "       ['s', 's']], \n",
       "      dtype='<U11')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = np.array([[1,2],['s','s']])\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = pool1.results()\n",
    "q = pool2.results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('Alice', -1,  5,  5), ('Bob',  3, -1,  5), ('Chuck',  1,  2, -1),\n",
       "       ('Alice', -1,  5,  5), ('Bob',  3, -1,  5), ('Chuck',  1,  2, -1)], \n",
       "      dtype=[('f0', '<U12'), ('f1', '<i8'), ('f2', '<i8'), ('f3', '<i8')])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = np.insert(p, p.shape[0] , q, axis=0)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('Alice', -1,  5,  5), ('Bob',  3, -1,  5), ('Chuck',  1,  2, -1)], \n",
       "      dtype=[('f0', '<U12'), ('f1', '<i8'), ('f2', '<i8'), ('f3', '<i8')])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "types = '<U12,i8,i8,i8'\n",
    "\n",
    "with open(\"./pool_test_csv.csv\") as f:\n",
    "    ncols = len(f.readline().split(','))\n",
    "pool = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=',', dtype=None, skip_header=1, usecols=range(1,ncols))\n",
    "names = np.genfromtxt(\"./pool_test_csv.csv\", delimiter=',', dtype='<U12', skip_header=1, usecols=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1,  5,  5],\n",
       "       [ 3, -1,  5],\n",
       "       [ 1,  2, -1]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alice'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 3 into shape (3,4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-5ba279b5c4eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 3 into shape (3,4)"
     ]
    }
   ],
   "source": [
    "pool.reshape((3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('Alice', -1,  5,  5), ('Bob',  3, -1,  5), ('Chuck',  1,  2, -1)], \n",
       "      dtype=[('f0', '<U12'), ('f1', '<i8'), ('f2', '<i8'), ('f3', '<i8')])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool1.results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = np.zeros(3)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', 'a', '2'], \n",
       "      dtype='<U11')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,'a',2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fd = {'Alice': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd['Alice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = [[1],[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k[1].append(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [2, 3]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p ={'k': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'t' in p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p['q'] =3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(p['s'])\n",
    "except:\n",
    "    p['s'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k': 3, 'q': 3, 's': 1}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def g():\n",
    "    return 3, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-147-8d2766aecf92>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "max([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = [(3,4),5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./test.log', 'wb') as file_object:\n",
    "        pickle.dump(x, file_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./test.log','rb') as file_object: \n",
    "    db = pickle.load(file_object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "k[3] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "k['a'] = {'t':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k['a']['t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
